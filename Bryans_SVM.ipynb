{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secret_data\n",
    "import json\n",
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start getting keys & secrets for running Twitter user, you will need your own user with details saved in a file named 'secret_data.txt' to run this\n",
    "CONSUMER_KEY = secret_data.CONSUMER_KEY\n",
    "CONSUMER_SECRET = secret_data.CONSUMER_SECRET\n",
    "ACCESS_TOKEN = secret_data.ACCESS_TOKEN\n",
    "ACCESS_SECRET = secret_data.ACCESS_SECRET\n",
    "#End getting keys & secrets for running Twitter user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start cache setup\n",
    "CACHE_FNAME = 'twitter_cache.json'\n",
    "try:\n",
    "    cache_file = open(CACHE_FNAME, 'r')\n",
    "    cache_contents = cache_file.read() #this is a str\n",
    "    CACHE_DICTION = json.loads(cache_contents) #this is a dict\n",
    "    cache_file.close()\n",
    "except:\n",
    "    CACHE_DICTION = {}\n",
    "#End cache setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start OAuth code\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "#End OAuth code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file containing tweet ids\n",
    "# FILENAME = 'test_tweet_ids_10.txt'\n",
    "FILENAME = 'test_tweet_ids.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start funct to grab vars from Tweet\n",
    "def get_tweet_vars(tweet):\n",
    "    try:\n",
    "        #set a number of vars for potential use\n",
    "        tweet_text = tweet['text']\n",
    "        tweet_in_reply_to_status_id_str = tweet['in_reply_to_status_id_str']\n",
    "        tweet_in_reply_to_screen_name = tweet['in_reply_to_screen_name']\n",
    "        tweet_entities_hashtags = tweet['entities']['hashtags']\n",
    "        tweet_entities_symbols = tweet['entities']['symbols']\n",
    "        tweet_entities_user_mentions = tweet['entities']['user_mentions']\n",
    "        tweet_entities_urls = tweet['entities']['urls']\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Exception in get_tweet_vars:{}\\nProblematic Tweet:{}\\n\\n'.format(e, tweet))\n",
    "#End funct to grab vars from Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start funct for cache check\n",
    "def get_tweet(found_id, label):\n",
    "    if found_id in CACHE_DICTION:\n",
    "        #if we get strange results in cache like missing child tweets then we may need to add the call to get_tweet() here\n",
    "        return CACHE_DICTION[found_id]\n",
    "#         if CACHE_DICTION[found_id]: #simple check if dict is populated or not\n",
    "#             get_tweet_vars(CACHE_DICTION[found_id])\n",
    "    else:\n",
    "        try:\n",
    "            resp = api.get_status(found_id) #resp is a class 'tweepy.models.Status'\n",
    "            json_str = json.dumps(resp._json) #json_str var is str type\n",
    "            json_obj = json.loads(json_str) #json_obj var is dict type\n",
    "        except Exception as e:\n",
    "            json_obj = {}\n",
    "            message = 'No worries. Empty entry has been made in cache.'\n",
    "            print('Exception in get_tweet:{}\\nProblematic Tweet:{}\\n\\n{}\\n'.format(e, found_id,message))\n",
    "        CACHE_DICTION[found_id] = json_obj #creating new entry in cache dict where key = 'found_id' & value = 'json_obj' which is a dict\n",
    "        CACHE_DICTION[found_id]['label'] = label\n",
    "        CACHE_DICTION[found_id]['original_related'] = 'original'\n",
    "        dumped_json_cache = json.dumps(CACHE_DICTION)\n",
    "        fw = open(CACHE_FNAME,\"w\")\n",
    "        fw.write(dumped_json_cache)\n",
    "        fw.close() # close the open file\n",
    "\n",
    "        #start recursive call to get_tweet() a.k.a. this funct if current tweet is in reply to another tweet\n",
    "        if CACHE_DICTION[found_id]['in_reply_to_status_id_str'] is not None:\n",
    "            in_reply_id = CACHE_DICTION[found_id]['in_reply_to_status_id_str']\n",
    "            get_tweet(in_reply_id) \n",
    "        #end recursive call to get_tweet()\n",
    "\n",
    "        return CACHE_DICTION[found_id]\n",
    "#         if CACHE_DICTION[found_id]: #simple check if dict is populated or not\n",
    "#             get_tweet_vars(CACHE_DICTION[found_id])\n",
    "#End funct for cache check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start funct to read in Tweet IDs from file\n",
    "def read_in_tweet_ids():\n",
    "    with open(FILENAME, 'r') as infile:\n",
    "        for line in infile:\n",
    "            found_id = line.split('\\t')[0]\n",
    "            label = line.split('\\t')[2] #label is needed for training of model\n",
    "            try:\n",
    "                get_tweet(found_id, label)\n",
    "            except:\n",
    "                pass #having exception message print here was causing duplicate messages when get_tweet failed\n",
    "#End funct to read in Tweet IDs from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = read_in_tweet_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert CACHE_DICTION to DF & transpose so it's more intuitive\n",
    "cache_df = pd.DataFrame(CACHE_DICTION).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip '\\n' char from label vals\n",
    "cache_df.label = cache_df.label.str.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clfr = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clfr', SVC(kernel='linear', class_weight='balanced'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

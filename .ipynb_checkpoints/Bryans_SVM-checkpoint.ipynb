{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PROPRIETARYNAME   NONPROPRIETARYNAME\n",
      "0      Sterile Diluent              diluent\n",
      "1               Amyvid     Florbetapir F 18\n",
      "2  Quinidine Gluconate  Quinidine Gluconate\n",
      "3            Trulicity          Dulaglutide\n",
      "4            Trulicity          Dulaglutide\n",
      "                     0                    1                    2  \\\n",
      "0      Sterile Diluent      sterile diluent      STERILE DILUENT   \n",
      "1               Amyvid               amyvid               AMYVID   \n",
      "2  Quinidine Gluconate  quinidine gluconate  QUINIDINE GLUCONATE   \n",
      "3            Trulicity            trulicity            TRULICITY   \n",
      "4             EMGALITY             emgality             EMGALITY   \n",
      "\n",
      "                     3  \n",
      "0              diluent  \n",
      "1     Florbetapir F 18  \n",
      "2  Quinidine Gluconate  \n",
      "3          Dulaglutide  \n",
      "4         galcanezumab  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import drugs\n",
    "from drugs import DRUGS_DIC, DRUGS_LIST\n",
    "import adverse\n",
    "from adverse import ADVERSE_DIC, PATIENT_FRIENDLY_DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline, this model gives F1 of 0.515\n",
    "SVM_clfr = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clfr', SVC(kernel='linear', class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "#baseline w default class_weight, this model gives F1 of 0.37\n",
    "# SVM_clfr = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clfr', SVC(kernel='linear'))\n",
    "#     ])\n",
    "\n",
    "#baseline w class_weight of .8/.2, this model gives F1 of 0\n",
    "# SVM_clfr = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clfr', SVC(kernel='linear', class_weight={0:.8, 1:.2}))\n",
    "#     ])\n",
    "\n",
    "#baseline w class_weight of .2/.8, this model gives F1 of 0.502\n",
    "# SVM_clfr = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clfr', SVC(kernel='linear', class_weight={0:.2, 1:.8}))\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training & test data, these are files Danny added to GH repo\n",
    "common_train = pd.read_csv('train-split.tsv', sep = '\\t')\n",
    "common_test = pd.read_csv('test-split.tsv', sep = '\\t')\n",
    "# common_whole = common_train.append(common_test) #just for EDA purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import list of drugs manually identified in train/test Tweets\n",
    "drug_list = pd.read_csv('Bryans_drug_list.csv')\n",
    "longer_drug_list = pd.read_csv('final_drugs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funct to iterate through tweet_text & set boolean to True if drug name present, can also return the drug name\n",
    "def flag_drug(tweet_text):\n",
    "    tweet_text_lower = tweet_text.lower()\n",
    "    split_tweet_text = tweet_text_lower.split()\n",
    "    \n",
    "    drug_flag = 0\n",
    "    for i in split_tweet_text:\n",
    "        if i in longer_drug_list['Lower'].values:\n",
    "            drug_flag = 1\n",
    "    return drug_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #funct to iterate through tweet_text & set boolean to True if drug name present, can also return the drug name\n",
    "# def flag_drug(tweet_text):\n",
    "#     tweet_text_lower = tweet_text.lower()\n",
    "#     split_tweet_text = tweet_text_lower.split()\n",
    "    \n",
    "#     drug_flag = 0\n",
    "#     for i in split_tweet_text:\n",
    "#         if i in drug_list['Lower'].values:\n",
    "#             drug_flag = 1\n",
    "#     return drug_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add col to train & test to flag Tweets with drugs\n",
    "common_train['drug_flag'] = common_train['tweet_text'].apply(flag_drug)\n",
    "common_test['drug_flag'] = common_test['tweet_text'].apply(flag_drug)\n",
    "# common_whole['drug_flag'] = common_whole['tweet_text'].apply(flag_drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using longer drug list\n",
    "#funct to iterate through tweet_text & count number of drug mentions\n",
    "def drug_count(tweet_text):\n",
    "    tweet_text_lower = tweet_text.lower()\n",
    "    split_tweet_text = tweet_text_lower.split()\n",
    "    \n",
    "    drug_count = 0\n",
    "    for i in split_tweet_text:\n",
    "        if i in longer_drug_list['Lower'].values:\n",
    "            drug_count += 1\n",
    "    return drug_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #funct to iterate through tweet_text & count number of drug mentions\n",
    "# def drug_count(tweet_text):\n",
    "#      tweet_text_lower = tweet_text.lower()\n",
    "#     split_tweet_text = tweet_text_lower.split()\n",
    "    \n",
    "#     drug_count = 0\n",
    "#     for i in split_tweet_text:\n",
    "#         if i in drug_list['Lower'].values:\n",
    "#             drug_count += 1\n",
    "#     return drug_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add col to train & test with count of drug mentions in tweet\n",
    "common_train['drug_count'] = common_train['tweet_text'].apply(drug_count)\n",
    "common_test['drug_count'] = common_test['tweet_text'].apply(drug_count)\n",
    "# common_whole['drug_count'] = common_whole['tweet_text'].apply(drug_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import list of ADRs manually identified in train/test Tweets\n",
    "adr_list = pd.read_csv('Bryans_ADR_list.csv', encoding='utf-8')\n",
    "longer_adr_list = pd.read_csv('final_adverse.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #funct to iterate through tweet_text & see if ADR present\n",
    "# def find_ADR(tweet_text):\n",
    "#     tweet_text_lower = tweet_text.lower()\n",
    "\n",
    "#     adr_flag = 0\n",
    "#     for i in adr_list['Lower'].values:\n",
    "#         if i in tweet_text_lower:\n",
    "#             adr_flag = 1      \n",
    "#     return adr_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using longer adverse list\n",
    "#funct to iterate through tweet_text & see if ADR present\n",
    "def find_ADR(tweet_text):\n",
    "    tweet_text_lower = tweet_text.lower()\n",
    "\n",
    "    adr_flag = 0\n",
    "    for i in longer_adr_list['adverse'].values:\n",
    "        if i in tweet_text_lower:\n",
    "            adr_flag = 1      \n",
    "    return adr_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add col to train & test to flag tweets with ADRs\n",
    "common_train['adr_flag'] = common_train['tweet_text'].apply(find_ADR)\n",
    "common_test['adr_flag'] = common_test['tweet_text'].apply(find_ADR)\n",
    "# common_whole['adr_flag'] = common_whole['tweet_text'].apply(find_ADR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #used to generate .corr heatmap\n",
    "# tweet_subset = common_whole.loc[:,['drug_flag', 'drug_count', 'adr_flag', 'adr_mention']]\n",
    "# import seaborn as sns\n",
    "# tweet_subset_matrix = tweet_subset.corr()\n",
    "# sns.heatmap(tweet_subset_matrix, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model to training data\n",
    "# SVM_clfr = SVM_clfr.fit(common_train['tweet_text'],common_train['adr_mention'])\n",
    "X = common_train['tweet_text']\n",
    "type(X)\n",
    "# SVM_clfr = SVM_clfr.fit(X= common_train[['tweet_text','tweet_id']], y = common_train['adr_mention']) #this throws a shape/# of samples error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting against training data until we have the train/test split available\n",
    "predicted = SVM_clfr.predict(common_test['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_test['predicted_label'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "f1 = f1_score(common_test['adr_mention'],predicted)\n",
    "precision = precision_score(common_test['adr_mention'],predicted)\n",
    "recall = recall_score(common_test['adr_mention'],predicted)\n",
    "accuracy = accuracy_score(common_test['adr_mention'],predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.515\n",
      "Precision: 0.431\n",
      "Recall: 0.639\n",
      "Accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "print('F1: {}\\nPrecision: {}\\nRecall: {}\\nAccuracy: {}'.format(round(f1,3), round(precision,3), round(recall,3), round(accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in files and concatenate them into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_1.tsv', delimiter = '\\t', header = None)\n",
    "set_2 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_2.tsv', delimiter = '\\t', header = None)\n",
    "set_3 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_3.tsv', delimiter = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "      <th>og_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343909778008973312</td>\n",
       "      <td>464336224</td>\n",
       "      <td>0</td>\n",
       "      <td>i don't fucking need humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352823276889837570</td>\n",
       "      <td>590337731</td>\n",
       "      <td>0</td>\n",
       "      <td>my retake is next friday, if i bloody fail aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339867818843594756</td>\n",
       "      <td>246979971</td>\n",
       "      <td>0</td>\n",
       "      <td>@doctorchristian scared to start fluoxetine, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349294537367236611</td>\n",
       "      <td>149749939</td>\n",
       "      <td>0</td>\n",
       "      <td>@intuitivegal1 ok, if you stopped taking the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354256195432882177</td>\n",
       "      <td>54516759</td>\n",
       "      <td>0</td>\n",
       "      <td>novartis announces secukinumab (ain457) demons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>352456944537178112</td>\n",
       "      <td>1267743056</td>\n",
       "      <td>1</td>\n",
       "      <td>\"u wailed all night; now y'r disembodied sobbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332479707004170241</td>\n",
       "      <td>273421529</td>\n",
       "      <td>0</td>\n",
       "      <td>@irapaps you're so fucking selfish. i've got l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>340660708364677120</td>\n",
       "      <td>135964180</td>\n",
       "      <td>1</td>\n",
       "      <td>not that anyone noticed, but my #ambienwithdra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>340523019967545344</td>\n",
       "      <td>420499836</td>\n",
       "      <td>0</td>\n",
       "      <td>@netnewsbuzz yes dear,now take ur prozac and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>343142864148103168</td>\n",
       "      <td>1189576320</td>\n",
       "      <td>0</td>\n",
       "      <td>popular antidepressants zoloft, prozac and pax...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     user_id  target  \\\n",
       "0  343909778008973312   464336224       0   \n",
       "1  352823276889837570   590337731       0   \n",
       "2  339867818843594756   246979971       0   \n",
       "3  349294537367236611   149749939       0   \n",
       "4  354256195432882177    54516759       0   \n",
       "5  352456944537178112  1267743056       1   \n",
       "6  332479707004170241   273421529       0   \n",
       "7  340660708364677120   135964180       1   \n",
       "8  340523019967545344   420499836       0   \n",
       "9  343142864148103168  1189576320       0   \n",
       "\n",
       "                                            og_tweet  \n",
       "0                        i don't fucking need humira  \n",
       "1  my retake is next friday, if i bloody fail aga...  \n",
       "2  @doctorchristian scared to start fluoxetine, w...  \n",
       "3  @intuitivegal1 ok, if you stopped taking the l...  \n",
       "4  novartis announces secukinumab (ain457) demons...  \n",
       "5  \"u wailed all night; now y'r disembodied sobbi...  \n",
       "6  @irapaps you're so fucking selfish. i've got l...  \n",
       "7  not that anyone noticed, but my #ambienwithdra...  \n",
       "8  @netnewsbuzz yes dear,now take ur prozac and c...  \n",
       "9  popular antidepressants zoloft, prozac and pax...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all three sets to one df\n",
    "one_two = pd.concat([set_1, set_2], ignore_index = True)\n",
    "df = pd.concat([one_two, set_3], ignore_index = True)\n",
    "df.columns = ['tweet_id', 'user_id', 'target', 'og_tweet']\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25678, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a unique list of everything that has a utf-code so that a dictionary can be made to replace them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['…', '•', '”', '—', '™', '“', '😵', '’', '🚘', '✨', '😳', '☺', '💊', '😴', '😕', '😐', '😒', '🍌', '👍', '–', '🙌', '❤', '😣', '😑', '✌', '😩', '😎', '😂', '✅', '👌', '🍸', '😰', '❏', '💉', '💆', '👽', '💤', '\\u200f', '😫', '🎶', '😋', '😁', '💋', '✋', '👋', '💯', '😈', '―', '😔', '😡', '🙅', '😘', '🌀', '👺', '😦', '😟', '‘', '😖', '😥', '↑', '🙊', '🙈', '🌠', '⚡', '🚂', '💨', '😃', '😬', '◆', '🔫', '😪', '💰', '😭', '😍', '👿', '😆', '✔', '👎', '🚬', '📝', '😤', '☀', '😉', '😱', '♥', '🌝', '💩', '👯', '👏', '☝', '😮', '😲', '😞', '😏', '🙋', '🍕', '🍔', '🍟', '🍗', '🍝', '🍤', '€', '🌚', '💔', '😢', '😷', '🚫', '👉', '😺', '😛', '😌', '⊙', '‿', '✿', '😙', '😗', '😊', '↓', '😅', '💁', '👲', '💘', '😜', '💖', '✗', '②', '⬆', '♫', '♡', '🐘', '🐗', '🐒', '👸', '🔥', '🌿', '👐', '💪', '😠', '🐧', '➔', '🙇', '🎧', '😨', '😝', '💃', '‼', '😓', '😹', '💀', '🔬', '💭', '➡', '🙍', '🚮', '👵', '😧', '⭐', '👀', '≥', '≤', '💸', '🌸', '💥', '😶', '⃣', '😄', '💫', '🔪', '\\u2006', '👮', '🙆', '🏀', '👭', '🙀', '🙏', '⛽', '🏼', '🎄', '👠', '🍁', '😯', '🌄', '💗', '🔙', '🔚', '🔜', '🎁', '🎅', '⛄', '🏃', '🎥', '🐶', '💓', '🌼', '😀', '💍', '💕', '😚', '🎉', '🎇', '🎆', '🎈', '☹', '💜', '🐸', '☕', '‑', '🔌', '🐈', '📷', '👴', '👧', '👬', '🍓', '👹', '💚', '⭕', '👊', '👇', '🍭', '😾', '≠', '😇', '🙉', '🍜', '🐥', '❗', '🌙', '⁰', '✖', '⬇', '🏂', '⚓', '👼', '♪', '🍻', '🐰', '💙', '❌']\n"
     ]
    }
   ],
   "source": [
    "emoji_lst = []\n",
    "for i in df['og_tweet']:\n",
    "    for emoji in re.findall(u'[\\U0001f300-\\U0001f700]|[\\u2000-\\u3000]', i):\n",
    "        if emoji not in emoji_lst:\n",
    "            emoji_lst.append(emoji)\n",
    "\n",
    "print (emoji_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoji_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {'…': '...', '•': '', '”': '\"', '—': '-', '™': '', '“': '\":', '😵': '<dizzy>', '’': \"'\", '✨': '<sparkles>', \n",
    "    '😳': '<flushed>', '☺': '<smile>', '💊': '<pill>', '😴': '<sleeping>', '😕': '<confused>', '😐': '<neutral>', \n",
    "    '😒': '<unamused>', '🍌': '<banana>', '👍': '<thumbsup>', '–': '-', '🙌': '<raisinghands>','❤': '<heart>', \n",
    "    '😣': '<perservering>', '😑': '<expressionless>', '✌': '<victoryhand>', '😩': '<weary>', '😎': '<sunglasses>', \n",
    "    '😂': '<laughing>', '✅': '<checkmark>', '👌': '<okhand>', '🍸': '<cocktail>','😰': '<coldsweat>', '❏': '', \n",
    "    '💉': '<syringe>', '💆': '<massage>', '👽': '<alien>', '💤': '<sleeping>', '\\u200f': '', '😫': '<tired>', \n",
    "    '🎶': '<musicnotes>', '😋': '<delicious>', '😁': '<grinning>', '💋': '<kiss>', '✋': '<raisedhand>', \n",
    "    '👋': '<wavinghand>', '💯': '<100>', '😈': '<smilingdevil>', '―': '-', '😔': '<pensive>', '😡': '<pouting>', \n",
    "    '🙅': '<no>', '😘': '<kissyface>', '🌀': '<cyclone>', '👺': '<goblin>', '😦': '<frowning>', '😟': '<worried>', '‘': \"'\", \n",
    "    '😖': '<confounded>', '😥': '<disappointed>', '↑': '<uparrow>', '🙊': '<speaknoevil>', '🙈': '<seenoevil>', \n",
    "    '🌠': '<shootingstar>', '⚡': '<voltage>', '💨': '<dash>', '😃': '<smiling>', '😬': '<grimace>', '◆': '<diamond>', \n",
    "    '🔫': '<pistol>', '😪': '<sleepy>', '💰': '<moneybag>', '😭': '<crying>', '😍': '<hearteyes>', '👿': '<frowningdevil>',\n",
    "    '😆': '<smiling>', '✔': '<checkmark>', '👎': '<thumbsdown>', '📝': '<memo>', '😤': '<triumph>', '☀': '*', \n",
    "    '😉': '<winking>', '😱': '<fear>', '♥': '<heart>', '🌝': '<fullmoon>', '💩': '<poop>', '👯': '<friendship>', \n",
    "    '👏': '<clap>', '☝': '<pointup>', '😮': '<openmouth>', '😲': '<astonished>', '😞': '<disappointed>', '😏': '<smirking>',\n",
    "    '🙋': '<raisinghand>', '🍕': '<pizza>', '🍔': '<hamburger>', '🍟': '<fries>', '🍗': '<chicken>', '🍝': '<spaghetti>', \n",
    "    '🍤': '<shrimp>', '€': '<euro>', '🌚': '<newmoon>', '💔': '<brokenheart>', '😢': '<crying>', '😷': '<facemask>', \n",
    "    '👉': '<pointright>', '😺': '<smile>', '😛': '<tongue>', '😌': '<relieved>', '⊙': '*', '‿': '_', '✿': '*', \n",
    "    '😙': '<kissyface>', '😗': '<kissyface>', '😊': '<smile>', '↓': '<downarrow>', '😅': '<sweat>', '💁': '<sassy>', \n",
    "    '👲': '<chinesecap>', '💘': '<heartarrow>', '😜': '<wink>', '💖': '<heart>', '✗': '<x>', '②': '<2>', '⬆': '<uparrow>',\n",
    "    '♫': '<music>', '♡': '<heart>', '🐘': '<elephant>', '🐗': '<boar>', '🐒': '<monkey>', '👸': '<queen>', '🔥': '<fire>',\n",
    "    '🌿': '<herb>', '👐': '<openhands>', '💪': '<muscle>', '😠': '<angry>', '🐧': '<penguin>', '➔': '<rightarrow>', \n",
    "    '🙇': '<bowing>', '🎧': '<headphones>', '😨': '<fearful>', '😝': '<tongue>', '💃': '<dancing>', '‼': '!!', \n",
    "    '😓': '<coldsweat>', '😹': '<laughing>', '💀': '<skull>', '🔬': '<microscope>', '💭': '<thought>', '➡': '<rightarrow>',\n",
    "    '🙍': '<frown>', '👵': '<old>', '😧': '<anguished>', '⭐': '<star>', '👀': '<eyes>', '≥': ' greater than ', '≤': ' less than ', \n",
    "    '💸': '<money>', '🌸': '<flower>', '💥': '<collision>', '😶': '<nomouth>', '⃣': '', '😄': '<smile>', '💫': '<dizzy>',\n",
    "    '🔪': '<knife>', '\\u2006': '', '👮': '<police>', '🙆': '<ok>', '🏀': '<basketball>', '👭': '<friendship>', \n",
    "    '🙀': '<weary>', '🙏': '<pray>', '⛽': '<fuel>', '🏼': '', '🎄': '<tree>', '👠': '<shoe>', '🍁': '<leaf>', \n",
    "    '😯': '<hushed>', '🌄': '<sunrise>', '💗': '<heart>', '🔙': '<back>', '🔚': '<end>', '🔜': '<soon>', '🎁': '<present>', \n",
    "    '🎅': '<santa>', '⛄': '<snowman>', '🏃': '<run>', '🎥': '<camera>', '🐶': '<dog>', '💓': '<heart>', '🌼': '<flower>', \n",
    "    '😀': '<smile>', '💍': '<ring>', '💕': '<heart>', '😚': '<kissyface>', '🎉': '<party>', '🎇': '<firework>', \n",
    "    '🎆': '<firework>', '🎈': '<balloon>', '☹': '<frown>', '💜': '<heart>', '🐸': '<frog>', '☕': '<tea>', '‑': '-', \n",
    "    '🔌': '<plug>', '🐈': '<cat>', '📷': '<camera>', '👴': '<old>', '👧': '<young>', '👬': '<friendship>', '🍓': '<strawberry>',\n",
    "    '👹': '<ogre>', '💚': '<heart>', '⭕': '<circle>', '👊': '<fist<', '👇': '<pointdown>', '🍭': '<lolipop>', \n",
    "    '😾': '<pouting>', '≠': ' does not equal ', '😇': '<innocent>', '🙉': '<hearnoevil>', '🍜': '<ramen>', '🐥': '<chick>',\n",
    "    '❗': '!', '🌙': '<moon>', '⁰': '^0', '✖': 'x', '⬇': '<downarrow>', '🏂': '<surf>', '⚓': '<anchor>', '👼': '<angel>',\n",
    "    '♪': '<music>', '🍻': '<beer>', '🐰': '<bunny>', '💙': '<heart>', '❌': 'x', '🚘': '<car>', '🚂':'<train>', \n",
    "    '🚬': '<cigarette>','🚫': '<noentry>', '🚮': '<litter>'}\n",
    "\n",
    "# just wanted to make sure I got them all lol\n",
    "for emoji in emoji_lst:\n",
    "    if emoji not in emoji_dict.keys():\n",
    "        print(emoji)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_lst = df['og_tweet'].to_list()\n",
    "\n",
    "cleaned = []\n",
    "for tweet in og_lst:\n",
    "    cleaned.append(re.sub(u'[\\U0001f300-\\U0001f700]|[\\u2000-\\u3000]', lambda m: ' ' + emoji_dict.get(m.group()) + ' ',tweet))\n",
    "\n",
    "df['no_utf'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "      <th>og_tweet</th>\n",
       "      <th>no_utf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>535492308817682432</td>\n",
       "      <td>330650218</td>\n",
       "      <td>1</td>\n",
       "      <td>@twittalesskels 😂😂😂😂 i'm high off this tamiflu...</td>\n",
       "      <td>@twittalesskels  &lt;laughing&gt;  &lt;laughing&gt;  &lt;laug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id    user_id  target  \\\n",
       "25677  535492308817682432  330650218       1   \n",
       "\n",
       "                                                og_tweet  \\\n",
       "25677  @twittalesskels 😂😂😂😂 i'm high off this tamiflu...   \n",
       "\n",
       "                                                  no_utf  \n",
       "25677  @twittalesskels  <laughing>  <laughing>  <laug...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

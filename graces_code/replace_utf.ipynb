{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in files and concatenate them into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_1.tsv', delimiter = '\\t', header = None)\n",
    "set_2 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_2.tsv', delimiter = '\\t', header = None)\n",
    "set_3 = pd.read_csv('/Users/graceganzel/Desktop/School/LHS712/SMM4H/TraininData_Subtask1_WithTweets/training_set_3.tsv', delimiter = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "      <th>og_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343909778008973312</td>\n",
       "      <td>464336224</td>\n",
       "      <td>0</td>\n",
       "      <td>i don't fucking need humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352823276889837570</td>\n",
       "      <td>590337731</td>\n",
       "      <td>0</td>\n",
       "      <td>my retake is next friday, if i bloody fail aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339867818843594756</td>\n",
       "      <td>246979971</td>\n",
       "      <td>0</td>\n",
       "      <td>@doctorchristian scared to start fluoxetine, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349294537367236611</td>\n",
       "      <td>149749939</td>\n",
       "      <td>0</td>\n",
       "      <td>@intuitivegal1 ok, if you stopped taking the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354256195432882177</td>\n",
       "      <td>54516759</td>\n",
       "      <td>0</td>\n",
       "      <td>novartis announces secukinumab (ain457) demons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>352456944537178112</td>\n",
       "      <td>1267743056</td>\n",
       "      <td>1</td>\n",
       "      <td>\"u wailed all night; now y'r disembodied sobbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332479707004170241</td>\n",
       "      <td>273421529</td>\n",
       "      <td>0</td>\n",
       "      <td>@irapaps you're so fucking selfish. i've got l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>340660708364677120</td>\n",
       "      <td>135964180</td>\n",
       "      <td>1</td>\n",
       "      <td>not that anyone noticed, but my #ambienwithdra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>340523019967545344</td>\n",
       "      <td>420499836</td>\n",
       "      <td>0</td>\n",
       "      <td>@netnewsbuzz yes dear,now take ur prozac and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>343142864148103168</td>\n",
       "      <td>1189576320</td>\n",
       "      <td>0</td>\n",
       "      <td>popular antidepressants zoloft, prozac and pax...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     user_id  target  \\\n",
       "0  343909778008973312   464336224       0   \n",
       "1  352823276889837570   590337731       0   \n",
       "2  339867818843594756   246979971       0   \n",
       "3  349294537367236611   149749939       0   \n",
       "4  354256195432882177    54516759       0   \n",
       "5  352456944537178112  1267743056       1   \n",
       "6  332479707004170241   273421529       0   \n",
       "7  340660708364677120   135964180       1   \n",
       "8  340523019967545344   420499836       0   \n",
       "9  343142864148103168  1189576320       0   \n",
       "\n",
       "                                            og_tweet  \n",
       "0                        i don't fucking need humira  \n",
       "1  my retake is next friday, if i bloody fail aga...  \n",
       "2  @doctorchristian scared to start fluoxetine, w...  \n",
       "3  @intuitivegal1 ok, if you stopped taking the l...  \n",
       "4  novartis announces secukinumab (ain457) demons...  \n",
       "5  \"u wailed all night; now y'r disembodied sobbi...  \n",
       "6  @irapaps you're so fucking selfish. i've got l...  \n",
       "7  not that anyone noticed, but my #ambienwithdra...  \n",
       "8  @netnewsbuzz yes dear,now take ur prozac and c...  \n",
       "9  popular antidepressants zoloft, prozac and pax...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all three sets to one df\n",
    "one_two = pd.concat([set_1, set_2], ignore_index = True)\n",
    "df = pd.concat([one_two, set_3], ignore_index = True)\n",
    "df.columns = ['tweet_id', 'user_id', 'target', 'og_tweet']\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25678, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a unique list of everything that has a utf-code so that a dictionary can be made to replace them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â€¦', 'â€¢', 'â€', 'â€”', 'â„¢', 'â€œ', 'ğŸ˜µ', 'â€™', 'ğŸš˜', 'âœ¨', 'ğŸ˜³', 'â˜º', 'ğŸ’Š', 'ğŸ˜´', 'ğŸ˜•', 'ğŸ˜', 'ğŸ˜’', 'ğŸŒ', 'ğŸ‘', 'â€“', 'ğŸ™Œ', 'â¤', 'ğŸ˜£', 'ğŸ˜‘', 'âœŒ', 'ğŸ˜©', 'ğŸ˜', 'ğŸ˜‚', 'âœ…', 'ğŸ‘Œ', 'ğŸ¸', 'ğŸ˜°', 'â', 'ğŸ’‰', 'ğŸ’†', 'ğŸ‘½', 'ğŸ’¤', '\\u200f', 'ğŸ˜«', 'ğŸ¶', 'ğŸ˜‹', 'ğŸ˜', 'ğŸ’‹', 'âœ‹', 'ğŸ‘‹', 'ğŸ’¯', 'ğŸ˜ˆ', 'â€•', 'ğŸ˜”', 'ğŸ˜¡', 'ğŸ™…', 'ğŸ˜˜', 'ğŸŒ€', 'ğŸ‘º', 'ğŸ˜¦', 'ğŸ˜Ÿ', 'â€˜', 'ğŸ˜–', 'ğŸ˜¥', 'â†‘', 'ğŸ™Š', 'ğŸ™ˆ', 'ğŸŒ ', 'âš¡', 'ğŸš‚', 'ğŸ’¨', 'ğŸ˜ƒ', 'ğŸ˜¬', 'â—†', 'ğŸ”«', 'ğŸ˜ª', 'ğŸ’°', 'ğŸ˜­', 'ğŸ˜', 'ğŸ‘¿', 'ğŸ˜†', 'âœ”', 'ğŸ‘', 'ğŸš¬', 'ğŸ“', 'ğŸ˜¤', 'â˜€', 'ğŸ˜‰', 'ğŸ˜±', 'â™¥', 'ğŸŒ', 'ğŸ’©', 'ğŸ‘¯', 'ğŸ‘', 'â˜', 'ğŸ˜®', 'ğŸ˜²', 'ğŸ˜', 'ğŸ˜', 'ğŸ™‹', 'ğŸ•', 'ğŸ”', 'ğŸŸ', 'ğŸ—', 'ğŸ', 'ğŸ¤', 'â‚¬', 'ğŸŒš', 'ğŸ’”', 'ğŸ˜¢', 'ğŸ˜·', 'ğŸš«', 'ğŸ‘‰', 'ğŸ˜º', 'ğŸ˜›', 'ğŸ˜Œ', 'âŠ™', 'â€¿', 'âœ¿', 'ğŸ˜™', 'ğŸ˜—', 'ğŸ˜Š', 'â†“', 'ğŸ˜…', 'ğŸ’', 'ğŸ‘²', 'ğŸ’˜', 'ğŸ˜œ', 'ğŸ’–', 'âœ—', 'â‘¡', 'â¬†', 'â™«', 'â™¡', 'ğŸ˜', 'ğŸ—', 'ğŸ’', 'ğŸ‘¸', 'ğŸ”¥', 'ğŸŒ¿', 'ğŸ‘', 'ğŸ’ª', 'ğŸ˜ ', 'ğŸ§', 'â”', 'ğŸ™‡', 'ğŸ§', 'ğŸ˜¨', 'ğŸ˜', 'ğŸ’ƒ', 'â€¼', 'ğŸ˜“', 'ğŸ˜¹', 'ğŸ’€', 'ğŸ”¬', 'ğŸ’­', 'â¡', 'ğŸ™', 'ğŸš®', 'ğŸ‘µ', 'ğŸ˜§', 'â­', 'ğŸ‘€', 'â‰¥', 'â‰¤', 'ğŸ’¸', 'ğŸŒ¸', 'ğŸ’¥', 'ğŸ˜¶', 'âƒ£', 'ğŸ˜„', 'ğŸ’«', 'ğŸ”ª', '\\u2006', 'ğŸ‘®', 'ğŸ™†', 'ğŸ€', 'ğŸ‘­', 'ğŸ™€', 'ğŸ™', 'â›½', 'ğŸ¼', 'ğŸ„', 'ğŸ‘ ', 'ğŸ', 'ğŸ˜¯', 'ğŸŒ„', 'ğŸ’—', 'ğŸ”™', 'ğŸ”š', 'ğŸ”œ', 'ğŸ', 'ğŸ…', 'â›„', 'ğŸƒ', 'ğŸ¥', 'ğŸ¶', 'ğŸ’“', 'ğŸŒ¼', 'ğŸ˜€', 'ğŸ’', 'ğŸ’•', 'ğŸ˜š', 'ğŸ‰', 'ğŸ‡', 'ğŸ†', 'ğŸˆ', 'â˜¹', 'ğŸ’œ', 'ğŸ¸', 'â˜•', 'â€‘', 'ğŸ”Œ', 'ğŸˆ', 'ğŸ“·', 'ğŸ‘´', 'ğŸ‘§', 'ğŸ‘¬', 'ğŸ“', 'ğŸ‘¹', 'ğŸ’š', 'â­•', 'ğŸ‘Š', 'ğŸ‘‡', 'ğŸ­', 'ğŸ˜¾', 'â‰ ', 'ğŸ˜‡', 'ğŸ™‰', 'ğŸœ', 'ğŸ¥', 'â—', 'ğŸŒ™', 'â°', 'âœ–', 'â¬‡', 'ğŸ‚', 'âš“', 'ğŸ‘¼', 'â™ª', 'ğŸ»', 'ğŸ°', 'ğŸ’™', 'âŒ']\n"
     ]
    }
   ],
   "source": [
    "emoji_lst = []\n",
    "for i in df['og_tweet']:\n",
    "    for emoji in re.findall(u'[\\U0001f300-\\U0001f700]|[\\u2000-\\u3000]', i):\n",
    "        if emoji not in emoji_lst:\n",
    "            emoji_lst.append(emoji)\n",
    "\n",
    "print (emoji_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoji_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {'â€¦': '...', 'â€¢': '', 'â€': '\"', 'â€”': '-', 'â„¢': '', 'â€œ': '\":', 'ğŸ˜µ': '<dizzy>', 'â€™': \"'\", 'âœ¨': '<sparkles>', \n",
    "    'ğŸ˜³': '<flushed>', 'â˜º': '<smile>', 'ğŸ’Š': '<pill>', 'ğŸ˜´': '<sleeping>', 'ğŸ˜•': '<confused>', 'ğŸ˜': '<neutral>', \n",
    "    'ğŸ˜’': '<unamused>', 'ğŸŒ': '<banana>', 'ğŸ‘': '<thumbsup>', 'â€“': '-', 'ğŸ™Œ': '<raisinghands>','â¤': '<heart>', \n",
    "    'ğŸ˜£': '<perservering>', 'ğŸ˜‘': '<expressionless>', 'âœŒ': '<victoryhand>', 'ğŸ˜©': '<weary>', 'ğŸ˜': '<sunglasses>', \n",
    "    'ğŸ˜‚': '<laughing>', 'âœ…': '<checkmark>', 'ğŸ‘Œ': '<okhand>', 'ğŸ¸': '<cocktail>','ğŸ˜°': '<coldsweat>', 'â': '', \n",
    "    'ğŸ’‰': '<syringe>', 'ğŸ’†': '<massage>', 'ğŸ‘½': '<alien>', 'ğŸ’¤': '<sleeping>', '\\u200f': '', 'ğŸ˜«': '<tired>', \n",
    "    'ğŸ¶': '<musicnotes>', 'ğŸ˜‹': '<delicious>', 'ğŸ˜': '<grinning>', 'ğŸ’‹': '<kiss>', 'âœ‹': '<raisedhand>', \n",
    "    'ğŸ‘‹': '<wavinghand>', 'ğŸ’¯': '<100>', 'ğŸ˜ˆ': '<smilingdevil>', 'â€•': '-', 'ğŸ˜”': '<pensive>', 'ğŸ˜¡': '<pouting>', \n",
    "    'ğŸ™…': '<no>', 'ğŸ˜˜': '<kissyface>', 'ğŸŒ€': '<cyclone>', 'ğŸ‘º': '<goblin>', 'ğŸ˜¦': '<frowning>', 'ğŸ˜Ÿ': '<worried>', 'â€˜': \"'\", \n",
    "    'ğŸ˜–': '<confounded>', 'ğŸ˜¥': '<disappointed>', 'â†‘': '<uparrow>', 'ğŸ™Š': '<speaknoevil>', 'ğŸ™ˆ': '<seenoevil>', \n",
    "    'ğŸŒ ': '<shootingstar>', 'âš¡': '<voltage>', 'ğŸ’¨': '<dash>', 'ğŸ˜ƒ': '<smiling>', 'ğŸ˜¬': '<grimace>', 'â—†': '<diamond>', \n",
    "    'ğŸ”«': '<pistol>', 'ğŸ˜ª': '<sleepy>', 'ğŸ’°': '<moneybag>', 'ğŸ˜­': '<crying>', 'ğŸ˜': '<hearteyes>', 'ğŸ‘¿': '<frowningdevil>',\n",
    "    'ğŸ˜†': '<smiling>', 'âœ”': '<checkmark>', 'ğŸ‘': '<thumbsdown>', 'ğŸ“': '<memo>', 'ğŸ˜¤': '<triumph>', 'â˜€': '*', \n",
    "    'ğŸ˜‰': '<winking>', 'ğŸ˜±': '<fear>', 'â™¥': '<heart>', 'ğŸŒ': '<fullmoon>', 'ğŸ’©': '<poop>', 'ğŸ‘¯': '<friendship>', \n",
    "    'ğŸ‘': '<clap>', 'â˜': '<pointup>', 'ğŸ˜®': '<openmouth>', 'ğŸ˜²': '<astonished>', 'ğŸ˜': '<disappointed>', 'ğŸ˜': '<smirking>',\n",
    "    'ğŸ™‹': '<raisinghand>', 'ğŸ•': '<pizza>', 'ğŸ”': '<hamburger>', 'ğŸŸ': '<fries>', 'ğŸ—': '<chicken>', 'ğŸ': '<spaghetti>', \n",
    "    'ğŸ¤': '<shrimp>', 'â‚¬': '<euro>', 'ğŸŒš': '<newmoon>', 'ğŸ’”': '<brokenheart>', 'ğŸ˜¢': '<crying>', 'ğŸ˜·': '<facemask>', \n",
    "    'ğŸ‘‰': '<pointright>', 'ğŸ˜º': '<smile>', 'ğŸ˜›': '<tongue>', 'ğŸ˜Œ': '<relieved>', 'âŠ™': '*', 'â€¿': '_', 'âœ¿': '*', \n",
    "    'ğŸ˜™': '<kissyface>', 'ğŸ˜—': '<kissyface>', 'ğŸ˜Š': '<smile>', 'â†“': '<downarrow>', 'ğŸ˜…': '<sweat>', 'ğŸ’': '<sassy>', \n",
    "    'ğŸ‘²': '<chinesecap>', 'ğŸ’˜': '<heartarrow>', 'ğŸ˜œ': '<wink>', 'ğŸ’–': '<heart>', 'âœ—': '<x>', 'â‘¡': '<2>', 'â¬†': '<uparrow>',\n",
    "    'â™«': '<music>', 'â™¡': '<heart>', 'ğŸ˜': '<elephant>', 'ğŸ—': '<boar>', 'ğŸ’': '<monkey>', 'ğŸ‘¸': '<queen>', 'ğŸ”¥': '<fire>',\n",
    "    'ğŸŒ¿': '<herb>', 'ğŸ‘': '<openhands>', 'ğŸ’ª': '<muscle>', 'ğŸ˜ ': '<angry>', 'ğŸ§': '<penguin>', 'â”': '<rightarrow>', \n",
    "    'ğŸ™‡': '<bowing>', 'ğŸ§': '<headphones>', 'ğŸ˜¨': '<fearful>', 'ğŸ˜': '<tongue>', 'ğŸ’ƒ': '<dancing>', 'â€¼': '!!', \n",
    "    'ğŸ˜“': '<coldsweat>', 'ğŸ˜¹': '<laughing>', 'ğŸ’€': '<skull>', 'ğŸ”¬': '<microscope>', 'ğŸ’­': '<thought>', 'â¡': '<rightarrow>',\n",
    "    'ğŸ™': '<frown>', 'ğŸ‘µ': '<old>', 'ğŸ˜§': '<anguished>', 'â­': '<star>', 'ğŸ‘€': '<eyes>', 'â‰¥': ' greater than ', 'â‰¤': ' less than ', \n",
    "    'ğŸ’¸': '<money>', 'ğŸŒ¸': '<flower>', 'ğŸ’¥': '<collision>', 'ğŸ˜¶': '<nomouth>', 'âƒ£': '', 'ğŸ˜„': '<smile>', 'ğŸ’«': '<dizzy>',\n",
    "    'ğŸ”ª': '<knife>', '\\u2006': '', 'ğŸ‘®': '<police>', 'ğŸ™†': '<ok>', 'ğŸ€': '<basketball>', 'ğŸ‘­': '<friendship>', \n",
    "    'ğŸ™€': '<weary>', 'ğŸ™': '<pray>', 'â›½': '<fuel>', 'ğŸ¼': '', 'ğŸ„': '<tree>', 'ğŸ‘ ': '<shoe>', 'ğŸ': '<leaf>', \n",
    "    'ğŸ˜¯': '<hushed>', 'ğŸŒ„': '<sunrise>', 'ğŸ’—': '<heart>', 'ğŸ”™': '<back>', 'ğŸ”š': '<end>', 'ğŸ”œ': '<soon>', 'ğŸ': '<present>', \n",
    "    'ğŸ…': '<santa>', 'â›„': '<snowman>', 'ğŸƒ': '<run>', 'ğŸ¥': '<camera>', 'ğŸ¶': '<dog>', 'ğŸ’“': '<heart>', 'ğŸŒ¼': '<flower>', \n",
    "    'ğŸ˜€': '<smile>', 'ğŸ’': '<ring>', 'ğŸ’•': '<heart>', 'ğŸ˜š': '<kissyface>', 'ğŸ‰': '<party>', 'ğŸ‡': '<firework>', \n",
    "    'ğŸ†': '<firework>', 'ğŸˆ': '<balloon>', 'â˜¹': '<frown>', 'ğŸ’œ': '<heart>', 'ğŸ¸': '<frog>', 'â˜•': '<tea>', 'â€‘': '-', \n",
    "    'ğŸ”Œ': '<plug>', 'ğŸˆ': '<cat>', 'ğŸ“·': '<camera>', 'ğŸ‘´': '<old>', 'ğŸ‘§': '<young>', 'ğŸ‘¬': '<friendship>', 'ğŸ“': '<strawberry>',\n",
    "    'ğŸ‘¹': '<ogre>', 'ğŸ’š': '<heart>', 'â­•': '<circle>', 'ğŸ‘Š': '<fist<', 'ğŸ‘‡': '<pointdown>', 'ğŸ­': '<lolipop>', \n",
    "    'ğŸ˜¾': '<pouting>', 'â‰ ': ' does not equal ', 'ğŸ˜‡': '<innocent>', 'ğŸ™‰': '<hearnoevil>', 'ğŸœ': '<ramen>', 'ğŸ¥': '<chick>',\n",
    "    'â—': '!', 'ğŸŒ™': '<moon>', 'â°': '^0', 'âœ–': 'x', 'â¬‡': '<downarrow>', 'ğŸ‚': '<surf>', 'âš“': '<anchor>', 'ğŸ‘¼': '<angel>',\n",
    "    'â™ª': '<music>', 'ğŸ»': '<beer>', 'ğŸ°': '<bunny>', 'ğŸ’™': '<heart>', 'âŒ': 'x', 'ğŸš˜': '<car>', 'ğŸš‚':'<train>', \n",
    "    'ğŸš¬': '<cigarette>','ğŸš«': '<noentry>', 'ğŸš®': '<litter>'}\n",
    "\n",
    "# just wanted to make sure I got them all lol\n",
    "for emoji in emoji_lst:\n",
    "    if emoji not in emoji_dict.keys():\n",
    "        print(emoji)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_lst = df['og_tweet'].to_list()\n",
    "\n",
    "cleaned = []\n",
    "for tweet in og_lst:\n",
    "    cleaned.append(re.sub(u'[\\U0001f300-\\U0001f700]|[\\u2000-\\u3000]', lambda m: ' ' + emoji_dict.get(m.group()) + ' ',tweet))\n",
    "\n",
    "df['no_utf'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "      <th>og_tweet</th>\n",
       "      <th>no_utf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>535492308817682432</td>\n",
       "      <td>330650218</td>\n",
       "      <td>1</td>\n",
       "      <td>@twittalesskels ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ i'm high off this tamiflu...</td>\n",
       "      <td>@twittalesskels  &lt;laughing&gt;  &lt;laughing&gt;  &lt;laug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id    user_id  target  \\\n",
       "25677  535492308817682432  330650218       1   \n",
       "\n",
       "                                                og_tweet  \\\n",
       "25677  @twittalesskels ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ i'm high off this tamiflu...   \n",
       "\n",
       "                                                  no_utf  \n",
       "25677  @twittalesskels  <laughing>  <laughing>  <laug...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
